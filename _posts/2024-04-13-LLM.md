---
title: "A wishlist of \"LLM alchemy\" that I want to learn"
date: 2024-04-13
---

Working with LLMs is pretty much like doing a bit of alchemy, especially prompt engineering.  

## What I want to learn to do: 
 
1. Communicate with LLMs via API and for batch processing of tasks. (and ways to control the output format)

        Example: Send it a bunch of student resposne and have it grade them.

        Update: Successfully learned out to do this one for grading a bunch of student responses. Several detailed posts coming soon.

3. Text Embedding + clustering using LLM.

        Example: Can we use this technique to find patterns in student response? I have some ideas on how to do it, and have some student data laying around.

4. Making a function call to an external agent/program using LLMs.

        Example: LLMs alone are terrible at doing math. However, with function calling I can request that the LLM communicate with, for example, a python symbolic manipulater, to help it with doing math.

5. Retrieval Augmented Generation (RAG).

        Exmple usecase: Have LLMs search through a table of learning objectives and tag problems/resources with those LOs.  

2. Setting up a small language model (SLM) from HuggingFace on a local or cloud cluster. 

        Update: Given how cheap GPT-4o is, and how much better the performances are, I don't think it is particularly worthwile to setup a SLM, unless I'm developing a tutor chatbot. 

1. Moonshot: Finding a GenAI model that can generate/process SVG images.


---

<script src="https://utteranc.es/client.js"
        repo="Zhongzhou/the-learning-plumber"
        issue-term="pathname"
        theme="boxy-light"
        crossorigin="anonymous"
        label = "blog-comment"
        async>
</script>